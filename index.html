<!DOCTYPE html>
<html lang="en">
    <head>
        <title>One Policy to Run Them All</title>
        <link rel="stylesheet" href="custom.css">
    </head>

    <body>
        <h1 hidden></h1>

        <script src="https://kit.fontawesome.com/02e2ed10b8.js" crossorigin="anonymous"></script>
		<script async src="https://unpkg.com/es-module-shims@1.6.3/dist/es-module-shims.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
        <script type="importmap">
            { "imports": { "three": "./node_modules/three/build/three.module.js", "three/addons/": "./node_modules/three/examples/jsm/"} }
        </script>
        <script type="module" src="script.js"></script>

        <div>
            <div id="title-container">
                <p id="paper-title">
                    One Policy to Run Them All: an End-to-end Learning<br>Approach to Multi-Embodiment Locomotion
                </p>
                <div id="authors">
                    <a class="author" href="https://www.ias.informatik.tu-darmstadt.de/Team/NicoBohlinger" target="_blank">Nico Bohlinger<sup>1</sup></a>
                    <a class="author" href="https://ideas-ncbr.pl/osoby/grzegorz-czechmanowski/" target="_blank">Grzegorz Czechmanowski<sup>2</sup></a>
                    <a class="author" href="https://openreview.net/profile?id=~Maciej_Piotr_Krupka1" target="_blank">Maciej Krupka<sup>2</sup></a>
                    <a class="author" href="https://ideas-ncbr.pl/en/osoby/piotr-kicki/" target="_blank">Piotr Kicki<sup>2</sup></a>
                    <a class="author" href="https://ideas-ncbr.pl/osoby/krzysztof-walas/" target="_blank">Krzysztof Walas<sup>2</sup></a>
                    <a class="author" href="https://www.ias.informatik.tu-darmstadt.de/Team/JanPeters" target="_blank">Jan Peters<sup>1</sup></a>
                    <a class="author" href="https://www.ias.informatik.tu-darmstadt.de/Team/DavideTateo" target="_blank">Davide Tateo<sup>1</sup></a>
                </div>
                <div id="affiliations">
                    <p class="affiliation"><sup>1</sup>Technical University of Darmstadt</p>
                    <p class="affiliation"><sup>2</sup>Poznan University of Technology</p>
                </div>

                <p id="conference-name">Conference on Robot Learning (CoRL) 2024</p>
            </div>

            <div id="social-buttons">
                <a href="https://github.com/nico-bohlinger/one_policy_to_run_them_all" target="_blank" class="social-button">
                    <i class="fa fa-github"></i>
                    <p>Code</p>
                </a>
                <a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/NicoBohlinger/one_policy_to_run_them_all.pdf" target="_blank" class="social-button">
                    <i class="fa fa-file-pdf"></i>
                    <p>Paper</p>
                </a>
                <a href="https://www.ias.informatik.tu-darmstadt.de/uploads/Team/NicoBohlinger/one_policy_to_run_them_all.pdf" target="_blank" class="social-button">
                    <i class="fa fa-youtube"></i>
                    <p>Video</p>
                </a>
            </div>

            <div id="tldr-container">
                <p id="tldr-text"><span id="tldr-first">TLDR:</span> We propose the Unified Robot Morpholgy Architecture (URMA) that can learn a single general locomotion policy for any legged robot embodiment and morphology.</p>
            </div>
            
            <div class="section-container">
                <p class="section-header">Interactive Simulation</p>
                <p class="section-text">
                    Test our single multi-embodiment policy trained with URMA interactively in your browser.
                    We provide 9 out of the 16 robots from the training set for you to try out.
                    Use the controls panel to change the robot and the target velocities, use the camera controls to take a closer look and reset the simulation to put the robot back in its starting position.
                </p>
            </div>
            <div id="canvas-container">
                Loading...
            </div>

            <div class="section-container">
                <p class="section-header">Unified Robot Morpholgy Architecture</p>
                <p class="section-text">
                    To handle observations of any morphology, URMA splits observations into robot-specific and general parts.
                    Robot-specific observations are joint (and foot) observations.
                    They have the same structure for all joints but vary in their number depending on the robot.
                    We can only use fixed length vectors in neural networks, so we want a mechanism that can take any joint observation and route it into a long latent vector that holds the information of all joints.
                </p>
                <p class="section-text">
                    To do this routing, a "language" is needed that can describe a given joint such that the neural network can figure out where to put which joint observation in the latent vector.
                    URMA uses joint description vectors made out of multiple characteristic joint properties like the jointâ€™s rotation axis, its relative nominal position, velocity limits, control range, etc. to describe any given joint.
                </p>
                <p class="section-text">
                    In practice, URMA implements the observation routing with a simple attention encoder where the joint description vectors act as the keys and the joint observations as the values of the attention mechanism.
                </p>
                <img src="images/website_architecture_1.png" alt="URMA architecture" class="section-image">
                <p class="section-text">
                    The same attention encoding is used for the foot observations and the resulting joint and feet latent vectors are concatenated with the general observations and passed to the policies big core network.
                </p>
                <img src="images/website_architecture_2.png" alt="URMA architecture" class="section-image">
                <p class="section-text">
                    Finally, we use our universal morphology decoder, which takes the output of the core network and pairs it with the batch of joint descriptions and single joint latents to produce the final action for given every joint.
            </div>

            <div class="section-container">
                <p class="section-header">Training in Simulation</p>
                <p class="section-text">
                    The URMA policy is trained in simulation on 16 different robots simultaneously.
                    Its training set contains 9 quadrupeds, 6 bipeds / humanoids and 1 hexapod.
                    The policy is trained with Proximal Policy Optimization (PPO) implemented in <a href="https://github.com/nico-bohlinger/RL-X" target="_blank">RL-X</a> for 100M simulation steps per robot.
                    In simulation, the trained policy outperforms typical multi-task RL approaches and shows strong robustness and zero-shot capabilities.
                </p>
                <video controls class="section-video">
                    <source src="videos/training_simulation.mp4" type="video/mp4">
                </video>
            </div>

            <div class="section-container">
                <p class="section-header">Deployment in the Real World</p>
                <p class="section-text">
                    After training in simulation, the policy is deployed on two quadruped robots from the training set in the real world.
                    The extensive domain randomization during training enables the policy to be directly transferred to real robots without any further adaptation.
                <video controls class="section-video">
                    <source src="videos/real_world_seen_robots.mp4" type="video/mp4">
                </video>
            </div>

            <div class="section-container">
                <p class="section-header">Deployment on Unseen Robots</p>
                <p class="section-text">
                    Through the big variety of robots in the training set, the randomization of their properties and the morphology-agnostic URMA architecture, the policy can generalize to new robots never seen in the training process.
                </p>
                <video controls class="section-video">
                    <source src="videos/real_world_unseen_robots.mp4" type="video/mp4">
                </video>
            </div>

            <div class="section-container">
                <p class="section-header">Acknowledgments</p>
                <p class="section-text">
                    This project was funded by National Science Centre, Poland under the OPUS call in the Weave programme UMO-2021/43/I/ST6/02711, and by the German Science Foundation (DFG) under grant number PE 2315/17-1. Part of the calculations were conducted on the Lichtenberg high performance computer at TU Darmstadt.
                </p>
            </div>
            
            <div id="website-inspiration">
                <p>This website was inspired by <a href="https://kzakka.com/robopianist/">Kevin Zakka's</a> and <a href="https://brentyi.github.io/tilted/">Brent Yi's</a>.</p>
            </div>
        </div>
    </body>
</html>
